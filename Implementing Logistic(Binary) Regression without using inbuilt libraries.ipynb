{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Dummifying target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,2:] = ((data.iloc[:,2:]- data.iloc[:,2:].min())/(data.iloc[:,2:].max()-data.iloc[:,2:].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[1]=='M',1] = 0 # mapping Malignant to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[1]=='B',1] = 1 #mapping Bening to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].value_counts() # Balanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:,2:], data[1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(logistic_score):\n",
    "    return 1 / (1 + np.exp(-logistic_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_score(ind_variables, coefficients):\n",
    "    logistic_score = np.dot(ind_variables, coefficients)\n",
    "    return logistic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(ind_variables, coefficients, dep_variable):\n",
    "    ll = np.sum(dep_variable*logistic_score(ind_variables, coefficients) - np.log(1 + np.exp(logistic_score(ind_variables, coefficients))) )\n",
    "    return ll    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(ind_variables, dep_variable, num_steps, learning_rate):\n",
    "    \n",
    "    coefficients = np.zeros(ind_variables.shape[1])\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        logistic_scores = logistic_score(ind_variables, coefficients)\n",
    "        predictions = activation(logistic_scores)\n",
    "\n",
    "        # Updating weights with respect to output error signals\n",
    "        output_error_signal = dep_variable - predictions\n",
    "        gradient = np.dot(ind_variables.T, output_error_signal)\n",
    "        coefficients += learning_rate * gradient\n",
    "        \n",
    "        # Checking log likelihood\n",
    "        if step % 10000 == 0:\n",
    "            print(log_likelihood(ind_variables, coefficients, dep_variable))\n",
    "        \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and accuracy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-315.21755214582754\n",
      "-133.67893353454517\n",
      "-112.50483197823763\n",
      "-100.9645695145076\n",
      "-93.21512620110084\n",
      "-87.51998199103748\n",
      "-83.10457954686657\n",
      "-79.55338598829337\n",
      "-76.61811493960617\n",
      "-74.1394517812425\n",
      "-72.00982399572293\n",
      "-70.153724154381\n",
      "-68.5164840253731\n",
      "-67.05749335590832\n",
      "-65.74591830771033\n",
      "-64.55790046108571\n",
      "-63.4746695957078\n",
      "-62.48123973507218\n",
      "-61.565488191129774\n",
      "-60.717492336210285\n",
      "-59.92904357992873\n",
      "-59.19328555282884\n",
      "-58.50444087416544\n",
      "-57.85760210430113\n",
      "-57.24856988090205\n",
      "-56.67372620644057\n",
      "-56.12993424732945\n",
      "-55.61445835791336\n",
      "-55.12489969761522\n",
      "-54.6591439891868\n"
     ]
    }
   ],
   "source": [
    "coefficients= logistic_regression(X_train, y_train, \n",
    "                     num_steps = 300000, learning_rate = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9604395604395605\n"
     ]
    }
   ],
   "source": [
    "final_scores = np.dot(X_train, coefficients)\n",
    "preds = np.round(activation(final_scores))\n",
    "\n",
    "print('Final Train Accuracy: {0}'.format((preds == y_train).sum().astype(float) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "final_scores = np.dot(X_test, coefficients)\n",
    "preds = np.round(activation(final_scores))\n",
    "\n",
    "print('Final test Accuracy: {0}'.format((preds == y_test).sum().astype(float) / len(preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
